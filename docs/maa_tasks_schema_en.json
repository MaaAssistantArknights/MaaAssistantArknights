{
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "maa task config english",
    "patternProperties": {
        "^(?!\\$)": {
            "type": "object",
            "oneOf": [
                {
                    "$ref": "#/definitions/JustReturnTask"
                },
                {
                    "$ref": "#/definitions/MatchTemplateTask"
                },
                {
                    "$ref": "#/definitions/OcrDetectTask"
                },
                {
                    "$ref": "#/definitions/FeatureMatchTask"
                }
            ]
        }
    },
    "definitions": {
        "Rectangle": {
            "type": "array",
            "maxItems": 4,
            "minItems": 4,
            "items": {
                "type": "number"
            }
        },
        "ParamsArray": {
            "type": "array",
            "items": {
                "type": "number"
            }
        },
        "TaskNameList": {
            "type": "array",
            "items": {
                "type": "string",
                "description": "Task to be performed"
            }
        },
        "BaseTask": {
            "properties": {
                "baseTask": {
                    "type": "string",
                    "description": "Optional, generates tasks based on other tasks as templates"
                },
                "algorithm": {
                    "type": "string",
                    "pattern": "JustReturn|MatchTemplate|OcrDetect|FeatureMatch",
                    "default": "MatchTemplate",
                    "description": "Optional, indicates the type of recognition algorithm, defaults to MatchTemplate"
                },
                "action": {
                    "type": "string",
                    "pattern": "ClickSelf|ClickRand|DoNothing|Stop|ClickRect|Swipe|Input",
                    "default": "DoNothing",
                    "description": "Optional, indicates the action to be taken after recognition\nDefaults to DoNothing when not filled in"
                },
                "inputText": {
                    "type": "string",
                    "default": "",
                    "description": "Optional, valid when action is Input, indicating the text to be entered"
                },
                "sub": {
                    "$ref": "#/definitions/TaskNameList",
                    "description": "Optional, subtask. Will execute each subtask in turn after executing the current task\nIt is possible to nest the sub-tasks, sub-tasks can be nested with sub-tasks. But be careful not to write a dead loop"
                },
                "subErrorIgnored": {
                    "type": "boolean",
                    "default": false,
                    "description": "Optional, whether or not to ignore errors from sub-tasks. Default is false\nIf false, if a subtask fails, the execution of subsequent tasks will not continue (equivalent to an error in this task)\nIf true, subtask errors have no effect on execution"
                },
                "next": {
                    "$ref": "#/definitions/TaskNameList",
                    "description": "Optional, indicates the next task to be executed after the current task\nIt will be identified from front to back, and the first matching task will be executed\nIf not filled in, the current task will be stopped by default"
                },
                "maxTimes": {
                    "type": "number",
                    "description": "Optional, indicates the maximum number of times the task can be executed\nDefault is infinite, if not filled in\nAfter reaching the maximum number of times, if there is exceededNext field, execute exceededNext; otherwise, the task will be stopped directly"
                },
                "exceededNext": {
                    "$ref": "#/definitions/TaskNameList",
                    "description": "Optional, indicates the task to be executed after reaching the maximum number of executions\nIf not filled in, it will stop when it reaches the maximum number of executions; If filled in, it will execute the tasks here, not the ones in next"
                },
                "onErrorNext": {
                    "$ref": "#/definitions/TaskNameList",
                    "description": "Optional, indicates the subsequent tasks to be executed in the event of an execution error"
                },
                "preDelay": {
                    "type": "number",
                    "description": "Optional, indicates how long the action will be delayed after recognition, in milliseconds; default is 0, if not filled in"
                },
                "postDelay": {
                    "type": "number",
                    "description": "Optional, indicates how long the action will be delayed before recognising next, in milliseconds; default is 0, if not filled in"
                },
                "roi": {
                    "$ref": "#/definitions/Rectangle",
                    "description": "Optional, indicates the recognition range, the format is [x, y, width, height]\nAutomatic scaling based on 1280 * 720; default [0, 0, 1280, 720]\nFill in as much as possible to reduce the recognition range. This can reduce performance consumption and speed up recognition"
                },
                "cache": {
                    "type": "boolean",
                    "default": true,
                    "description": "Optional, indicates whether the task uses caching, default is true;\nAfter the first recognition, the subsequent recognition will always be carried out only in the location of the first recognition, enabling this can greatly save performance\nBut it is only applicable for tasks where the target position will not change at all, if the target position to be recognised will change, please set it to false"
                },
                "rectMove": {
                    "$ref": "#/definitions/Rectangle",
                    "description": "Optional, move the target after recognition, this option is not recommended. Automatic scaling based on 1280 * 720\nFor example, if an A icon is recognised, but the actual location to be clicked is a position next to the A icon, then move it and click it. If possible, try to recognise the position to be clicked directly, this option is not recommended\nWhen the action is Swipe, it means the end of the swipe"
                },
                "reduceOtherTimes": {
                    "type": "array",
                    "items": {
                        "type": "string",
                        "description": "Task to be performed"
                    },
                    "description": "Optional, decrements the execution count of other tasks after execution"
                },
                "specificRect": {
                    "$ref": "#/definitions/Rectangle",
                    "description": "Valid and mandatory when the action is ClickRect, indicates the specified click position (a random point within the range), auto-scaling based on 1280 * 720\nValid and mandatory when the action is Swipe, indicates the starting point of the swipe"
                },
                "specialParams": {
                    "$ref": "#/definitions/ParamsArray",
                    "description": "Special parameters used for certain tasks (mostly handwritten thresholds, etc.)"
                },
                "highResolutionSwipeFix": {
                    "type": "boolean",
                    "default": false,
                    "description": "Optional, whether to enable high-resolution swipe fix, currently only needed for stage navigation which doesn't use unity swipe method, default is false"
                }
            },
            "allOf": [
                {
                    "if": {
                        "required": ["action"],
                        "properties": {
                            "action": {
                                "enum": ["ClickRect"]
                            }
                        }
                    },
                    "then": {
                        "required": ["specificRect"]
                    }
                },
                {
                    "if": {
                        "required": ["action"],
                        "properties": {
                            "action": {
                                "enum": ["Swipe"]
                            }
                        }
                    },
                    "then": {
                        "required": ["specificRect", "rectMove"]
                    }
                },
                {
                    "if": {
                        "properties": {
                            "algorithm": {
                                "const": "JustReturn"
                            },
                            "action": {
                                "const": "Input"
                            }
                        },
                        "required": ["algorithm", "action"]
                    },
                    "then": {
                        "required": ["inputText"]
                    }
                }
            ]
        },
        "JustReturnTask": {
            "allOf": [
                {
                    "$ref": "#/definitions/BaseTask"
                },
                {
                    "properties": {
                        "algorithm": {
                            "type": "string",
                            "pattern": "JustReturn"
                        }
                    },
                    "required": ["algorithm"]
                }
            ],
            "description": "Execute the action without recognition"
        },
        "MatchTemplateTask": {
            "allOf": [
                {
                    "$ref": "#/definitions/BaseTask"
                },
                {
                    "properties": {
                        "algorithm": {
                            "type": "string",
                            "pattern": "MatchTemplate"
                        }
                    }
                }
            ],
            "properties": {
                "template": {
                    "type": ["array", "string"],
                    "items": {
                        "type": "string"
                    },
                    "description": "Optional, the file name of the image to be matched\nDefaults to \"task name.png\" if not filled"
                },
                "templThreshold": {
                    "type": ["array", "number"],
                    "items": {
                        "type": "number"
                    },
                    "default": 0.8,
                    "description": "Optional, the threshold of the matching score of the template image, it is considered recognised if it exceeds the threshold\nDefaults to 0.8, you can check what the actual score is based on the log"
                },
                "maskRange": {
                    "type": "array",
                    "maxItems": 2,
                    "minimum": 2,
                    "items": {
                        "type": "number"
                    },
                    "default": [1, 255],
                    "description": "Optional, grey scale mask range. For example, paint the part of the image that does not need to be recognised as black (grey value is 0), and then set [1, 255], the blackened part will be ignored when matching"
                },
                "colorScales": {
                    "type": "array",
                    "description": "Required when method is HSVCount or RGBCount, color mask ranges\nStructure is [[lower1, upper1], [lower2, upper2], ...]\nInner layer is int for grayscale, or array<int, 3> for three-channel color (RGB or HSV based on method)\nMiddle layer is color (or grayscale) lower and upper limits\nOuter layer represents different color ranges, recognition area is their union on template image",
                    "items": {
                        "type": "array",
                        "minItems": 2,
                        "maxItems": 2
                    }
                },
                "colorWithClose": {
                    "type": "boolean",
                    "default": true,
                    "description": "Optional when method is HSVCount or RGBCount, default true\nWhether to use morphological closing on mask range for color counting\nClosing fills small black dots, generally improves color matching but set false for text"
                },
                "method": {
                    "type": ["array", "string"],
                    "items": {
                        "type": "string"
                    },
                    "default": "Ccoeff",
                    "enum": ["Ccoeff", "RGBCount", "HSVCount"],
                    "description": "Optional, template matching algorithm, can be list\nDefault is Ccoeff when not specified\n- Ccoeff: Color-insensitive template matching, corresponds to cv::TM_CCOEFF_NORMED\n- RGBCount: Color-sensitive template matching, binary thresholds target area and template using colorScales, calculates similarity using F1-score in RGB color space, then dot products result with Ccoeff result\n- HSVCount: Similar to RGBCount, but uses HSV color space"
                }
            },
            "description": "Match image"
        },
        "OcrDetectTask": {
            "allOf": [
                {
                    "$ref": "#/definitions/BaseTask"
                },
                {
                    "properties": {
                        "algorithm": {
                            "type": "string",
                            "pattern": "OcrDetect"
                        }
                    }
                }
            ],
            "properties": {
                "text": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Mandatory, the text content to be recognised, as long as any one of them matches, it is considered to have been recognised"
                },
                "fullMatch": {
                    "type": "boolean",
                    "default": false,
                    "description": "Optional, whether the text recognition needs to match all the words (can't match more than one word), the default is false\nfalse, as long as a substring can be found: for example, text: [\"Start\"], the actual recognition of \"Start action\" is also considered successful;\ntrue, it must recognise \"Start\", not one word more"
                },
                "isAscii": {
                    "type": "boolean",
                    "default": false,
                    "description": "Optional, whether text content is ASCII characters\nDefault false"
                },
                "ocrReplace": {
                    "type": "array",
                    "items": {
                        "type": "array",
                        "minItems": 2,
                        "maxItems": 2,
                        "items": {
                            "type": "string"
                        }
                    },
                    "description": "Optional, replacement of commonly misrecognised text (supports regex)"
                },
                "withoutDet": {
                    "type": "boolean",
                    "default": false,
                    "description": "Optional, whether to skip detection model\nDefault false"
                },
                "useRaw": {
                    "type": "boolean",
                    "default": true,
                    "description": "Optional, whether to use the original image for matching.\nDefault is true. If false, grayscale image matching will be used.\nThis is only effective when algorithm is OcrDetect and withoutDet is false."
                },
                "binThresholdLower": {
                    "type": "integer",
                    "default": 140,
                    "description": "Optional, lower threshold for grayscale binarisation (default 140).\nPixels with a grayscale value lower than this will be considered background and excluded from the text region.\nThis is only effective when algorithm is OcrDetect and withoutDet is false."
                },
                "binThresholdUpper": {
                    "type": "integer",
                    "default": 255,
                    "description": "Optional, upper threshold for grayscale binarisation (default 255).\nPixels with a grayscale value higher than this will be considered background and excluded from the text region.\nOnly pixels within the [lower, upper] range will be kept as text foreground.\nThis is only effective when algorithm is OcrDetect and withoutDet is false."
                }
            },
            "description": "Text recognition",
            "required": ["algorithm", "text"]
        },
        "FeatureMatchTask": {
            "allOf": [
                {
                    "$ref": "#/definitions/BaseTask"
                },
                {
                    "properties": {
                        "algorithm": {
                            "type": "string",
                            "pattern": "FeatureMatch"
                        }
                    },
                    "required": ["algorithm"]
                }
            ],
            "properties": {
                "template": {
                    "type": "string",
                    "description": "Optional, the file name of the image to be matched\nDefaults to \"task name.png\" if not filled"
                },
                "count": {
                    "type": "integer",
                    "minimum": 1,
                    "default": 4,
                    "description": "Required feature point count (threshold), default = 4"
                },
                "ratio": {
                    "type": "number",
                    "minimum": 0,
                    "maximum": 1.0,
                    "default": 0.6,
                    "description": "KNN matching algorithm distance ratio, [0 - 1.0], higher means looser matching, easier line connection. Default 0.6"
                },
                "detector": {
                    "type": "string",
                    "enum": ["SIFT", "ORB", "BRISK", "KAZE", "AKAZE", "SURF"],
                    "default": "SIFT",
                    "description": "Feature point detector type. Default is SIFT. Options: SIFT, ORB, BRISK, KAZE, AKAZE, SURF\nSIFT: High computational complexity, has scale and rotation invariance. Best effect.\nORB: Very fast computation, has rotation invariance but no scale invariance.\nBRISK: Very fast computation, has scale and rotation invariance.\nKAZE: Suitable for 2D and 3D images, has scale and rotation invariance.\nAKAZE: Fast computation, has scale and rotation invariance."
                }
            },
            "description": "Use feature point algorithm for image matching"
        }
    }
}
